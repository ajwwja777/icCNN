{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 import part\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST # Training dataset\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Class Gen\n",
    "def get_generator_block(input_dim, output_dim):\n",
    "\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=64, im_dim=(512, 14, 14), hidden_dim=128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            get_generator_block(z_dim, hidden_dim),\n",
    "            get_generator_block(hidden_dim, hidden_dim * 2),\n",
    "            get_generator_block(hidden_dim * 2, hidden_dim * 4),\n",
    "            get_generator_block(hidden_dim * 4, hidden_dim * 8),\n",
    "            nn.Linear(hidden_dim * 8, im_dim[0] * im_dim[1] * im_dim[2]),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, noise):\n",
    "        return self.gen(noise).view(noise.shape[0], *im_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Class Disc\n",
    "def get_discriminator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "         nn.Linear(input_dim, output_dim), #Layer 1\n",
    "         nn.LeakyReLU(0.2, inplace=True)\n",
    "    )\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, im_dim=(512, 14, 14), hidden_dim=128):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            get_discriminator_block(np.prod(im_dim), hidden_dim * 4),\n",
    "            get_discriminator_block(hidden_dim * 4, hidden_dim * 2),\n",
    "            get_discriminator_block(hidden_dim * 2, hidden_dim),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, image):\n",
    "        return self.disc(image.view(image.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 func getLoss\n",
    "def get_disc_loss(gen, disc, criterion, real, num_images, z_dim, device):\n",
    "    fake_noise = get_noise(num_images, z_dim, device=device)\n",
    "    fake = gen(fake_noise)\n",
    "\n",
    "    disc_fake_pred = disc(fake.detach())\n",
    "    disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n",
    "    \n",
    "    disc_real_pred = disc(real)\n",
    "    disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n",
    "   \n",
    "    disc_loss = (disc_fake_loss + disc_real_loss) / 2\n",
    "    return disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 func getLoss\n",
    "def get_gen_loss(gen, disc, criterion, num_images, z_dim, device):\n",
    "    fake_noise = get_noise(num_images, z_dim, device=device)\n",
    "    fake = gen(fake_noise)\n",
    "    \n",
    "    disc_fake_pred = disc(fake)\n",
    "    gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n",
    "\n",
    "    return gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 func getNoise\n",
    "def get_noise(n_samples, z_dim, device='cpu'):\n",
    "    return torch.randn(n_samples, z_dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 func visualize\n",
    "def visualize_tsne(all_feature, RFtype):\n",
    "    # 平均池化降维，将特征向量从 (421, 512, 14, 14) 降维到 (421, 512)\n",
    "    # all_feature = np.mean(all_feature, axis=(2, 3))\n",
    "    if RFtype == \"real\":\n",
    "        # all_feature = np.mean(all_feature, axis=(0, 1))\n",
    "        pass\n",
    "    else:\n",
    "        all_feature = np.mean(all_feature, axis=(2, 3))\n",
    "\n",
    "    # 执行t-SNE降维\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    feature_tsne = tsne.fit_transform(all_feature)\n",
    "\n",
    "    # Visualize t-SNE results\n",
    "    plt.scatter(feature_tsne[:, 0], feature_tsne[:, 1], s=1)\n",
    "    plt.xlabel('t-SNE Dimension 1')\n",
    "    plt.ylabel('t-SNE Dimension 2')\n",
    "    plt.title(RFtype)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 hyperperameter and so on\n",
    "z_dim = 128\n",
    "batch_size = 128\n",
    "lr = 0.00001\n",
    "device = 'cpu'\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss() # 这里要改变\n",
    "gen = Generator(z_dim).to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\n",
    "disc = Discriminator().to(device) \n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)\n",
    "\n",
    "im_dim=(512, 14, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 dataset\n",
    "\"\"\"\n",
    "data = np.load(\"my_npz.npz\")\n",
    "all_feature = data['f_map']\n",
    "print(all_feature.shape)\n",
    "(421, 512, 14, 14)\n",
    "\n",
    "特征向量的形状 (421, 512, 14, 14) 表示特征图数据具有四个维度,\n",
    "分别是 (样本数, 通道数, 高度, 宽度)\n",
    "\"\"\"\n",
    "class FeatureDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.data = np.load(file_path)['f_map']  # 加载 npz 文件的特征图数据\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)  # 返回数据集的大小\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        return torch.tensor(sample, dtype=torch.float)  # 转换为 PyTorch 张量\n",
    "\n",
    "# 修改 DataLoader 的数据集为特征图的自定义 Dataset\n",
    "# (2546, 512, 14, 14)\n",
    "path1 = '../../Data/iccnn/vgg16/16_vgg_voc_multi_iccnn_200.npz'#multi_iccnn\n",
    "# (421, 512, 14, 14)\n",
    "path3 = '../../Data/iccnn/basic_fmap/vgg_download/vgg_voc_bird_lame1_c5_ep2499.npz'#bird_iccnn(论文用)\n",
    "# (2546, 2208, 7, 7)\n",
    "path4 = '../../Data/iccnn/densenet161/161_densenet_voc_multi_iccnn.npz'#multi_iccnn\n",
    "dataset = FeatureDataset(path1)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 train\n",
    "n_epochs = 100\n",
    "display_step = 19 * 10\n",
    "\n",
    "cur_step = 0\n",
    "mean_generator_loss = 0\n",
    "mean_discriminator_loss = 0\n",
    "gen_loss = False\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "  \n",
    "    # Dataloader returns the batches\n",
    "    for real in tqdm(dataloader):\n",
    "        cur_batch_size = len(real)\n",
    "\n",
    "        # Flatten the batch of real images from the dataset\n",
    "        real = real.view(cur_batch_size, -1).to(device)\n",
    "        disc_loss = get_disc_loss(gen, disc, criterion, real, cur_batch_size, z_dim, device)\n",
    "\n",
    "        ### Update discriminator ###\n",
    "        disc_opt.zero_grad()\n",
    "        disc_loss.backward(retain_graph=True)\n",
    "        disc_opt.step()\n",
    "\n",
    "        gen_loss = get_gen_loss(gen, disc, criterion, cur_batch_size, z_dim, device)\n",
    "        gen_opt.zero_grad()\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "\n",
    "        # Keep track of the average discriminator loss\n",
    "        mean_discriminator_loss += disc_loss.item() / display_step\n",
    "\n",
    "        # Keep track of the average generator loss\n",
    "        mean_generator_loss += gen_loss.item() / display_step\n",
    "\n",
    "        ### Visualization code ###\n",
    "        # if cur_step % display_step == 0 and cur_step > 0:\n",
    "        if cur_step % display_step == 0:\n",
    "            print(f\"Step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n",
    "            fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
    "            fake = gen(fake_noise)\n",
    "            fake_all_feature = fake.detach().cpu().numpy()\n",
    "            real_all_feature = real.detach().cpu().numpy()\n",
    "            visualize_tsne(fake_all_feature, \"fake\")\n",
    "            visualize_tsne(real_all_feature, \"real\")\n",
    "            mean_generator_loss = 0\n",
    "            mean_discriminator_loss = 0\n",
    "        cur_step += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
