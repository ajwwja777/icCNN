{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 import part\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST # Training dataset\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from Similar_Mask_Generate import SMGBlock\n",
    "from SpectralClustering import spectral_clustering\n",
    "from Tools import Cluster_loss\n",
    "\n",
    "CHANNEL_NUM = 512\n",
    "F_MAP_SIZE = 196\n",
    "center_num = 5\n",
    "T = 2\n",
    "STOP_CLUSTERING = 200\n",
    "lam = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Class Gen\n",
    "def get_generator_block(input_dim, output_dim):\n",
    "\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=64, im_dim=(512, 14, 14), hidden_dim=128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.smg = SMGBlock(channel_size = CHANNEL_NUM, f_map_size=F_MAP_SIZE)\n",
    "        self.gen = nn.Sequential(\n",
    "            get_generator_block(z_dim, hidden_dim),\n",
    "            get_generator_block(hidden_dim, hidden_dim * 2),\n",
    "            get_generator_block(hidden_dim * 2, hidden_dim * 4),\n",
    "            get_generator_block(hidden_dim * 4, hidden_dim * 8),\n",
    "            nn.Linear(hidden_dim * 8, im_dim[0] * im_dim[1] * im_dim[2]),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, noise, eval=False):\n",
    "        if eval:\n",
    "            return self.gen(noise).view(noise.shape[0], *im_dim)\n",
    "        noise = self.gen(noise).view(noise.shape[0], *im_dim)\n",
    "        corre_matrix = self.smg(noise)\n",
    "        return noise, corre_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Class Disc\n",
    "def get_discriminator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "         nn.Linear(input_dim, output_dim), #Layer 1\n",
    "         nn.LeakyReLU(0.2, inplace=True)\n",
    "    )\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, im_dim=(512, 14, 14), hidden_dim=128):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            get_discriminator_block(np.prod(im_dim), hidden_dim * 4),\n",
    "            get_discriminator_block(hidden_dim * 4, hidden_dim * 2),\n",
    "            get_discriminator_block(hidden_dim * 2, hidden_dim),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, image):\n",
    "        return self.disc(image.view(image.shape[0], -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 func getLoss\n",
    "def get_disc_loss(gen, disc, criterion, real, num_images, z_dim, device):\n",
    "    fake_noise = get_noise(num_images, z_dim, device=device)\n",
    "    fake = gen(fake_noise)\n",
    "\n",
    "    disc_fake_pred = disc(fake.detach())\n",
    "    disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n",
    "    \n",
    "    disc_real_pred = disc(real)\n",
    "    disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n",
    "   \n",
    "    disc_loss = (disc_fake_loss + disc_real_loss) / 2\n",
    "    return disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 func getLoss\n",
    "def get_gen_loss(gen, disc, criterion, num_images, z_dim, device):\n",
    "    fake_noise = get_noise(num_images, z_dim, device=device)\n",
    "    fake = gen(fake_noise)\n",
    "    \n",
    "    disc_fake_pred = disc(fake)\n",
    "    gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n",
    "\n",
    "    return gen_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6 func getNoise\n",
    "def get_noise(n_samples, z_dim, device='cpu'):\n",
    "    return torch.randn(n_samples,z_dim,device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7 func visualize\n",
    "def visualize_tsne(all_feature, RFtype):\n",
    "    # 平均池化降维，将特征向量从 (421, 512, 14, 14) 降维到 (421, 512)\n",
    "    # all_feature = np.mean(all_feature, axis=(2, 3))\n",
    "    if RFtype == \"real\":\n",
    "        # all_feature = np.mean(all_feature, axis=(0, 1))\n",
    "        pass\n",
    "    else:\n",
    "        all_feature = np.mean(all_feature, axis=(2, 3))\n",
    "\n",
    "    # 执行t-SNE降维\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    feature_tsne = tsne.fit_transform(all_feature)\n",
    "\n",
    "    # Visualize t-SNE results\n",
    "    plt.scatter(feature_tsne[:, 0], feature_tsne[:, 1], s=1)\n",
    "    plt.xlabel('t-SNE Dimension 1')\n",
    "    plt.ylabel('t-SNE Dimension 2')\n",
    "    plt.title(RFtype)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func offline_spectral_cluster\n",
    "def offline_spectral_cluster(net, train_data, dataname, num_images):\n",
    "    net.eval()\n",
    "    f_map = []\n",
    "    for _ in train_data:\n",
    "        fake_noise = get_noise(num_images, z_dim, device=device)\n",
    "        cur_fmap = net(fake_noise,eval=True)\n",
    "        cur_fmap = cur_fmap.cpu().numpy()\n",
    "        f_map.append(cur_fmap)\n",
    "\n",
    "    f_map = np.concatenate(f_map,axis=0)\n",
    "    sample, channel,_,_ = f_map.shape\n",
    "    f_map = f_map.reshape((sample,channel,-1))\n",
    "    mean = np.mean(f_map,axis=0)\n",
    "    cov = np.mean(np.matmul(f_map-mean,np.transpose(f_map-mean,(0,2,1))),axis=0)\n",
    "    diag = np.diag(cov).reshape(channel,-1)\n",
    "    correlation = cov/(np.sqrt(np.matmul(diag,np.transpose(diag,(1,0))))+1e-5)+1\n",
    "    ground_true, loss_mask_num, loss_mask_den = spectral_clustering(correlation,n_cluster=center_num)\n",
    "    return ground_true, loss_mask_num, loss_mask_den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8 hyperperameter and so on\n",
    "z_dim = 128\n",
    "batch_size = 128\n",
    "lr = 0.00001\n",
    "device = 'cpu'\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "gen = Generator(z_dim).to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\n",
    "disc = Discriminator().to(device) \n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)\n",
    "# gen_scheduler = torch.optim.lr_scheduler.StepLR(gen_opt, step_size=125, gamma=0.6)\n",
    "# disc_scheduler = torch.optim.lr_scheduler.StepLR(disc_opt, step_size=125, gamma=0.6)\n",
    "\n",
    "im_dim=(512, 14, 14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 9 dataset\n",
    "\"\"\"\n",
    "data = np.load(\"my_npz.npz\")\n",
    "all_feature = data['f_map']\n",
    "print(all_feature.shape)\n",
    "(421, 512, 14, 14)\n",
    "\n",
    "特征向量的形状 (421, 512, 14, 14) 表示特征图数据具有四个维度,\n",
    "分别是 (样本数, 通道数, 高度, 宽度)。\n",
    "\"\"\"\n",
    "class FeatureDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.data = np.load(file_path)['f_map']  # 加载 npz 文件的特征图数据\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)  # 返回数据集的大小\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        return torch.tensor(sample, dtype=torch.float)  # 转换为 PyTorch 张量\n",
    "\n",
    "# 修改 DataLoader 的数据集为特征图的自定义 Dataset\n",
    "# (2546, 512, 14, 14)\n",
    "path1 = '../../Data/iccnn/vgg16/16_vgg_voc_multi_iccnn_200.npz'#multi_iccnn\n",
    "# (421, 512, 14, 14)\n",
    "path3 = '../../Data/iccnn/basic_fmap/vgg_download/vgg_voc_bird_lame1_c5_ep2499.npz'#bird_iccnn(论文用)\n",
    "# (2546, 2208, 7, 7)\n",
    "path4 = '../../Data/iccnn/densenet161/161_densenet_voc_multi_iccnn.npz'#multi_iccnn\n",
    "dataset = FeatureDataset(path3)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 512, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for real in dataloader:\n",
    "    print(real.shape)\n",
    "    if i == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac5f9d6efe240258f93c86a95792533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m cur_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(real)\n\u001b[0;32m     19\u001b[0m fake_noise \u001b[38;5;241m=\u001b[39m get_noise(batch_size, z_dim, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m---> 20\u001b[0m _, _, corre \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfake_noise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43meval\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m loss_ \u001b[38;5;241m=\u001b[39m cs_loss\u001b[38;5;241m.\u001b[39mupdate(corre, loss_mask_num, loss_mask_den)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Flatten the batch of real images from the dataset\u001b[39;00m\n",
      "File \u001b[1;32md:\\Downloads\\Anaconda\\envs\\py310_cpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Downloads\\Anaconda\\envs\\py310_cpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 27\u001b[0m, in \u001b[0;36mGenerator.forward\u001b[1;34m(self, noise, eval)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen(noise)\u001b[38;5;241m.\u001b[39mview(noise\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39mim_dim)\n\u001b[0;32m     26\u001b[0m noise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen(noise)\u001b[38;5;241m.\u001b[39mview(noise\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39mim_dim)\n\u001b[1;32m---> 27\u001b[0m corre_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m noise, corre_matrix\n",
      "File \u001b[1;32md:\\Downloads\\Anaconda\\envs\\py310_cpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Downloads\\Anaconda\\envs\\py310_cpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Code\\python\\AllMethod\\icCNN\\icCNNwithGAN\\Similar_Mask_Generate.py:32\u001b[0m, in \u001b[0;36mSMGBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     30\u001b[0m f_mean_transposed \u001b[38;5;241m=\u001b[39m f_mean\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     31\u001b[0m Local \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(theta_x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m-\u001b[39mf_mean, theta_x\u001b[38;5;241m-\u001b[39mf_mean_transposed)\n\u001b[1;32m---> 32\u001b[0m diag \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m cov \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(Local\u001b[38;5;241m*\u001b[39mdiag,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mview(batch_size,channel,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     34\u001b[0m cov_transpose \u001b[38;5;241m=\u001b[39m cov\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32md:\\Downloads\\Anaconda\\envs\\py310_cpu\\lib\\site-packages\\torch\\cuda\\__init__.py:289\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    287\u001b[0m     )\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    292\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    293\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "\n",
    "# 10 train\n",
    "n_epochs = 100\n",
    "display_step = 19 * 10\n",
    "\n",
    "cur_step = 0\n",
    "mean_generator_loss = 0\n",
    "mean_discriminator_loss = 0\n",
    "gen_loss = False\n",
    "save_gt=[]\n",
    "cs_loss = Cluster_loss()\n",
    "\n",
    "for epoch in range(n_epochs): \n",
    "    if (epoch) % T==0 and epoch < STOP_CLUSTERING:\n",
    "        with torch.no_grad():\n",
    "            _, loss_mask_num, loss_mask_den = offline_spectral_cluster(gen, dataloader, None, batch_size)\n",
    "    # Dataloader returns the batches\n",
    "    for real in tqdm(dataloader):\n",
    "        cur_batch_size = len(real)\n",
    "        fake_noise = get_noise(batch_size, z_dim, device=device)\n",
    "        _, _, corre = gen(fake_noise, eval=False)\n",
    "        loss_ = cs_loss.update(corre, loss_mask_num, loss_mask_den)\n",
    "\n",
    "        # Flatten the batch of real images from the dataset\n",
    "        real = real.view(cur_batch_size, -1).to(device)\n",
    "        disc_loss = get_disc_loss(gen, disc, criterion, real, cur_batch_size, z_dim, device) + lam * loss_\n",
    "\n",
    "        ### Update discriminator ###\n",
    "        disc_opt.zero_grad()\n",
    "        disc_loss.backward(retain_graph=True)\n",
    "        disc_opt.step()\n",
    "\n",
    "        gen_loss = get_gen_loss(gen, disc, criterion, cur_batch_size, z_dim, device) + lam * loss_\n",
    "        gen_opt.zero_grad()\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "\n",
    "        # Keep track of the average discriminator loss\n",
    "        mean_discriminator_loss += disc_loss.item() / display_step\n",
    "\n",
    "        # Keep track of the average generator loss\n",
    "        mean_generator_loss += gen_loss.item() / display_step\n",
    "\n",
    "        ### Visualization code ###\n",
    "        # if cur_step % display_step == 0 and cur_step > 0:\n",
    "        if cur_step % display_step == 0:\n",
    "            print(f\"Step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n",
    "            fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
    "            fake = gen(fake_noise)\n",
    "            fake_all_feature = fake.detach().cpu().numpy()\n",
    "            real_all_feature = real.detach().cpu().numpy()\n",
    "            visualize_tsne(fake_all_feature, \"fake\")\n",
    "            visualize_tsne(real_all_feature, \"real\")\n",
    "            mean_generator_loss = 0\n",
    "            mean_discriminator_loss = 0\n",
    "        cur_step += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
